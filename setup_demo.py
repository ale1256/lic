import os
import numpy as np
import nibabel as nib
import joblib
from nilearn import datasets, maskers, connectome
from sklearn.svm import SVC
from sklearn.pipeline import Pipeline
from sklearn.preprocessing import StandardScaler

def create_structured_mock(file_path, diagnosis='PD'):
    """
    CreeazÄƒ un NIfTI 4D unde regiunile creierului sunt corelate diferit.
    PD: Regiunile 0 È™i 1 sunt identice (corelaÈ›ie 1.0)
    HC: Toate regiunile sunt zgomot independent (corelaÈ›ie ~0.0)
    """
    # 39 regiuni (atlas MSDL), 20 volume temporale
    n_regions = 39
    n_volumes = 50
    
    if diagnosis == 'PD':
        # GenerÄƒm semnal corelat
        signals = np.random.randn(n_volumes, n_regions)
        signals[:, 1] = signals[:, 0] # ForÈ›Äƒm corelaÈ›ie perfectÄƒ Ã®ntre regiunea 0 È™i 1
    else:
        # GenerÄƒm zgomot independent
        signals = np.random.randn(n_volumes, n_regions)

    # CreÄƒm o imagine 4D simbolicÄƒ (5x5x5 voxeli, 50 timp)
    # Punem semnalele Ã®n "voxeli" pentru ca masker-ul sÄƒ le extragÄƒ
    data = np.zeros((10, 10, 10, n_volumes))
    for i in range(n_regions):
        # Distribuim semnalul regiunii i Ã®n cÃ¢teva celule din matrice
        x, y, z = i % 10, (i // 10) % 10, i // 100
        data[x, y, z, :] = signals[:, i]

    img = nib.Nifti1Image(data.astype(np.float32), np.eye(4))
    nib.save(img, file_path)
    print(f"âœ… Creat fiÈ™ier {diagnosis}: {file_path}")

def train_demo_model():
    print("ðŸ§  Antrenare model bazat pe conectivitate...")
    
    # 1. Definim semnÄƒturile de conectivitate (741 trÄƒsÄƒturi)
    # CreÄƒm 10 exemple PD (corelaÈ›ie mare pe prima trÄƒsÄƒturÄƒ)
    X_pd = np.random.normal(0, 0.1, (10, 741))
    X_pd[:, 0] = 1.5 # SimbolizÄƒm corelaÈ›ia puternicÄƒ Ã®ntre reg 0 È™i 1
    
    # CreÄƒm 10 exemple HC (corelaÈ›ie micÄƒ peste tot)
    X_hc = np.random.normal(0, 0.1, (10, 741))
    X_hc[:, 0] = -1.5
    
    X = np.vstack([X_pd, X_hc])
    y = np.array([1]*10 + [0]*10)
    
    # 2. Pipeline-ul trebuie sÄƒ fie identic cu cel din lucrare
    model = Pipeline([
        ('scaler', StandardScaler()),
        ('svm', SVC(kernel='linear', probability=True))
    ])
    
    model.fit(X, y)
    
    # 3. Salvare
    dest_path = os.path.join('diagnosis', 'ml_models', 'pd_classifier.pkl')
    os.makedirs(os.path.dirname(dest_path), exist_ok=True)
    joblib.dump(model, dest_path)
    print(f"ðŸš€ Model salvat: {dest_path}")

if __name__ == "__main__":
    # CurÄƒÈ›Äƒm folderele
    os.makedirs('mocks', exist_ok=True)
    
    # GenerÄƒm fiÈ™ierele cu structurÄƒ internÄƒ diferitÄƒ
    create_structured_mock('mocks/pacient_pozitiv_PD.nii.gz', 'PD')
    create_structured_mock('mocks/subiect_sanatos_HC.nii.gz', 'HC')
    
    # AntrenÄƒm modelul sÄƒ recunoascÄƒ acea structurÄƒ
    train_demo_model()
    
    print("\nðŸ”¥ ACUM VA FUNCÈšIONA:")
    print("1. Upload 'pacient_pozitiv_PD.nii.gz' -> Parkinson's")
    print("2. Upload 'subiect_sanatos_HC.nii.gz' -> Healthy") 