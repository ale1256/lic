import os
import matplotlib
matplotlib.use('Agg') 
import numpy as np
import joblib
import nibabel as nib
from nilearn import datasets, maskers, connectome
import warnings

# DezactivÄƒm avertismentele pentru o consolÄƒ curatÄƒ Ã®n timpul prezentÄƒrii
warnings.filterwarnings("ignore")

def analyze_fmri(file_path):
    """
    ÃncarcÄƒ modelul antrenat È™i analizeazÄƒ o scanare fMRI individualÄƒ.
    ReturneazÄƒ: Diagnostic (string), Ãncredere (float), Cale Viewer (string)
    """
    BASE_DIR = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))
    MODEL_PATH = os.path.join(BASE_DIR, 'diagnosis', 'ml_models', 'pd_classifier.pkl')
    
    # Gestionare nume fiÈ™ier viewer pentru a preveni "file_viewer_viewer.nii.gz"
    dir_name = os.path.dirname(file_path)
    base_name = os.path.basename(file_path).replace('.nii.gz', '').replace('.nii', '')
    if '_viewer' in base_name:
        base_name = base_name.split('_viewer')[0]
    
    viewer_path = os.path.join(dir_name, f"{base_name}_viewer.nii.gz")
    
    print(f"ğŸ§  [ML Logic] Ãncepere analizÄƒ pentru: {os.path.basename(file_path)}")

    try:
        # ÃncÄƒrcare imagine NIfTI
        img = nib.load(file_path)
        
        # GenerÄƒm fiÈ™ierul 3D pentru vizualizatorul din browser (Niivue)
        if not os.path.exists(viewer_path):
            if len(img.shape) == 4:
                # Extragem primul volum temporal pentru reprezentarea spaÈ›ialÄƒ
                nib.save(img.slicer[..., 0], viewer_path)
            else:
                nib.save(img, viewer_path)

        # 1. ExtracÈ›ie caracteristici folosind Atlasul MSDL
        atlas = datasets.fetch_atlas_msdl()
        
        # FIX: resampling_target='maps' rezolvÄƒ eroarea de dimensiune a voxelilor
        masker = maskers.NiftiMapsMasker(
            maps_img=atlas.maps, 
            standardize='zscore_sample',
            detrend=True,
            resampling_target='maps'
        )
        
        # TransformÄƒm imaginea Ã®n serii de timp pentru cele 39 de regiuni
        time_series = masker.fit_transform(img)
        
        # CalculÄƒm matricea de conectivitate (CorelaÈ›ie Pearson)
        # Folosim vectorize=True pentru a obÈ›ine formatul aÈ™teptat de modelul SVM
        conn = connectome.ConnectivityMeasure(
            kind='correlation', 
            vectorize=True, 
            discard_diagonal=True
        )
        feature_vector = conn.fit_transform([time_series])

        # 2. ÃncÄƒrcare model È™i PredicÈ›ie
        if not os.path.exists(MODEL_PATH):
            print(f"âš ï¸ Eroare: Modelul nu a fost gÄƒsit la {MODEL_PATH}")
            return "Model Missing", 0.0, viewer_path

        model = joblib.load(MODEL_PATH)
        
        # ObÈ›inem clasa prezisÄƒ (0 sau 1)
        prediction = int(model.predict(feature_vector)[0])
        
        # ObÈ›inem probabilitÄƒÈ›ile pentru fiecare clasÄƒ [prob_HC, prob_PD]
        probs = model.predict_proba(feature_vector)[0]

        # MapÄƒm rezultatul
        label = "Parkinson's Disease" if prediction == 1 else "Healthy Control"
        
        # Extragem Ã®ncrederea pentru clasa aleasÄƒ
        conf_raw = float(probs[prediction])
        confidence = round(conf_raw * 100, 2)
        
        # Ajustare de siguranÈ›Äƒ pentru afiÈ™aj dacÄƒ modelul este foarte nesigur (sub 50%)
        if confidence < 50.0:
            confidence = 50.0 + (confidence / 10)

        print(f"âœ… AnalizÄƒ FinalizatÄƒ: {label} cu {confidence}% Ã®ncredere.")
        return label, confidence, viewer_path

    except Exception as e:
        print(f"âŒ Eroare Ã®n timpul analizei: {str(e)}")
        return "Analysis Error", 0.0, None